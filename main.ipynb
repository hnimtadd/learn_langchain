{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63f62878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "normal_llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0ebfa88-5bd8-4ae8-bc99-add7be798a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits len 459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\n",
    "        \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "\"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\",\n",
    "\"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "\"https://lilianweng.github.io/posts/2020-10-29-odqa/\",\n",
    "\"https://lilianweng.github.io/posts/2020-08-06-nas/\",\n",
    "\"https://lilianweng.github.io/posts/2018-05-05-drl-implementation/\"\n",
    "        ),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(\"splits len\", len(splits))\n",
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "32d805d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
    ")\n",
    "#HUMAN\n",
    "#You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "#Question: {question} \n",
    "#Context: {context} \n",
    "#Answer:\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80ce5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "normal_chain = create_stuff_documents_chain(llm=llm,prompt=prompt,output_parser=StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d618efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jailbreak prompting is a type of black-box attack that adversarially triggers Language Models (LLMs) to output harmful content that should have been mitigated. This attack relies on heuristic-based prompting to \"jailbreak\" the built-in safety of the model. Wei et al. (2023) outlined two failure modes of LLM safety to guide the design of jailbreak attacks.\n"
     ]
    }
   ],
   "source": [
    "# question from: https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\n",
    "response = rag_chain.invoke(\"What is Jailbreak Prompting?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "943c211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know what \"Jailbreak Prompting\" refers to.\n"
     ]
    }
   ],
   "source": [
    "split_message = [\n",
    "    {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\",\n",
    "    }]\n",
    "# split_message.extend([\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"content\": chunk.page_content,\n",
    "#     } for chunk in splits\n",
    "# ])\n",
    "split_message.extend(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is Jailbreak Prompting?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response = normal_llm.invoke(\n",
    "    input=split_message\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "response = parser.invoke(response)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
